{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shell for the functions needed for the gpt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data():\n",
    "    nietzsche_txt = open('new_nietzsche.txt', 'r', encoding='utf-8')\n",
    "    nietzsche = nietzsche_txt.read()\n",
    "    return nietzsche\n",
    "\n",
    "nietzsche = open_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer():\n",
    "    '''\n",
    "    Class that takes care of encoding and decoding the text\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, tokenizer_type = \"base\") -> None:\n",
    "        self.tokenizer_type = tokenizer_type\n",
    "        self.vocab_size = 0\n",
    "        self.all_characters = None\n",
    "        \n",
    "    def get_vocab_size(self):\n",
    "        return jnp.copy(self.vocab_size)\n",
    "        \n",
    "    def sort_characters(self, data):\n",
    "        self.all_characters = sorted(list(set(data)))\n",
    "        self.vocab_size = len(self.all_characters)\n",
    "    \n",
    "    def encode(self, text):\n",
    "        self.sort_characters(text)\n",
    "        encoded_text = []\n",
    "        if self.tokenizer_type == \"base\":\n",
    "            for c in text:\n",
    "                num = self.all_characters.index(c)\n",
    "                encoded_text.append(num)\n",
    "                \n",
    "        return jnp.asarray(encoded_text)\n",
    "    \n",
    "    def decode(self, encoded_text):\n",
    "        text = []\n",
    "        if self.tokenizer_type == \"base\":\n",
    "            for n in encoded_text:\n",
    "                char = self.all_characters[n]\n",
    "                text.append(char)\n",
    "            text = ''.join([str(item) for item in text])\n",
    "        \n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tokenizer_type=\"base\")\n",
    "data = tokenizer.encode(nietzsche)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What I am now going to relate is the history of the next two centuries.\n",
      "I shall describe what will \n"
     ]
    }
   ],
   "source": [
    "# test tokenizer\n",
    "print(tokenizer.decode(data[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting_data(data, split):\n",
    "    n = int(split * len(data))\n",
    "    training_data = data[:n]\n",
    "    validation_data = data[n:]\n",
    "    return training_data, validation_data\n",
    "\n",
    "training_data, validation_data = splitting_data(data, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71 70  1 71 62  1 79 65]\n",
      " [57 76  1 76 64 61  1 79]\n",
      " [ 1 76 71  1 76 64 61  0]\n",
      " [57 74 81  1 59 71 74 71]]\n"
     ]
    }
   ],
   "source": [
    "batchsize = 4\n",
    "blocksize = 8\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "def get_batch(command, batchsize, key, blocksize):\n",
    "    train_batches_data = []\n",
    "    eval_batches_data = []\n",
    "    if command == 'train':\n",
    "        b_data = training_data\n",
    "    else:\n",
    "        b_data = validation_data\n",
    "    for _ in range(batchsize):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        pos = jax.random.randint(key = subkey, shape = (), minval = 0, maxval = (len(b_data) - blocksize))\n",
    "        batch_data = b_data[pos:pos + blocksize]\n",
    "        train_batches_data.append(batch_data)\n",
    "        batch_data = b_data[pos+1: pos + blocksize +1]\n",
    "        eval_batches_data.append(batch_data)\n",
    "        key = subkey\n",
    "    \n",
    "    train_batches_data = jnp.stack(train_batches_data)\n",
    "    eval_batches_data = jnp.stack(eval_batches_data)\n",
    "    \n",
    "    return train_batches_data, eval_batches_data\n",
    "    \n",
    "train, evals = get_batch('train', batchsize, key, blocksize)\n",
    "print(train)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    vocab_size: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.token_embedding_table = nn.Embed(self.vocab_size, self.vocab_size)\n",
    "    \n",
    "    def __call__(self, train, evals= 'None'):\n",
    "        \n",
    "        logits = self.token_embedding_table(train)\n",
    "        if evals == 'None':\n",
    "            mean_loss = None\n",
    "        else:\n",
    "            b, t, c = logits.shape\n",
    "            logits = logits.reshape((b*t, c))\n",
    "            labels = evals.reshape((b*t))\n",
    "            labels_one_hot = jax.nn.one_hot(labels, num_classes=self.vocab_size)\n",
    "            loss = optax.losses.softmax_cross_entropy(logits=logits, labels=labels_one_hot)\n",
    "            mean_loss = loss.mean()\n",
    "        return logits, mean_loss\n",
    "    \n",
    "    def generate(self, train, length):\n",
    "        key = jax.random.PRNGKey(43)\n",
    "        for _ in length:\n",
    "            logits, _ = self(train)\n",
    "            logits = logits[:,-1,:]\n",
    "            probabilities = jax.nn.softmax(logits)\n",
    "            key, subkey = jax.random.split(key)\n",
    "            next_logit = jax.random.choice(subkey, logits, p = probabilities)\n",
    "            key = subkey\n",
    "            train = jax.numpy.concatenate((train, next_logit), axis = 1)\n",
    "        return train\n",
    "            \n",
    "    \n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "m = BaseModel(vocab_size = vocab_size)\n",
    "params = m.init(jax.random.PRNGKey(0), train, evals) \n",
    "s, loss = m.apply(params, train, evals)\n",
    "print(tokenizer.decode(m.generate(train = jax.numpy.zeros((1,1)), length = 100)))\n",
    "print(s.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAttentionHead():\n",
    "    '''\n",
    "    One attention head\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention():\n",
    "    '''\n",
    "    Multiple attention heads combined together\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
