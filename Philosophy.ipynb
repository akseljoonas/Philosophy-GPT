{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1a73fc1-7eaf-4af0-856b-705d89352886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import numpy.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723c08ec-0243-4403-9a2f-2472bf8e064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data():\n",
    "    nietzsche_txt = open('/Users/mikaumana/PycharmProjects/NietzscheGPT/new_nietzsche.txt', 'r', encoding='utf-8')\n",
    "    nietzsche = nietzsche_txt.read()\n",
    "    return nietzsche\n",
    "\n",
    "nietzsche = open_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5e5aee5-210b-4724-82fc-9645d65449e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_characters(data):\n",
    "    chararacters = sorted(list(set(data)))\n",
    "    return chararacters\n",
    "\n",
    "all_characters = sort_characters(nietzsche)\n",
    "vocab_size = len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e37dd3a-b7ab-4e7b-98b4-4d4746e4c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, all_characters):\n",
    "    encoded_text = []\n",
    "    for c in text:\n",
    "        num = all_characters.index(c)\n",
    "        encoded_text.append(num)\n",
    "    return encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b41f3b2-35ae-4a61-a213-6befecc42a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(encoded_text, all_characters):\n",
    "    text = []\n",
    "    for n in encoded_text:\n",
    "        char = all_characters[n]\n",
    "        text.append(char)\n",
    "    string = ''.join([str(item) for item in text])\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b38dd27-e176-4bb1-8c31-2cce7b186666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3396780,) int32\n"
     ]
    }
   ],
   "source": [
    "def encoding_nietzsche(data, all_characters):\n",
    "    encoded_data = jax.numpy.asarray(encode(data, all_characters))\n",
    "    print(encoded_data.shape, encoded_data.dtype)\n",
    "    return encoded_data\n",
    "\n",
    "data = encoding_nietzsche(nietzsche, all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35623a39-f6ab-43b4-9a00-0173e9733869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n"
     ]
    }
   ],
   "source": [
    "def splitting_data(data, split):\n",
    "    n = int(split * len(data))\n",
    "    training_data = data[:n]\n",
    "    validation_data = data[n:]\n",
    "    return training_data, validation_data\n",
    "\n",
    "training_data, validation_data = splitting_data(data, 0.9)\n",
    "print(validation_data.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1018e26b-e8c4-46ca-9ac3-3c29f2be7fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75  0 71 62  1 75 72 65]\n",
      " [ 1 76 64 61  1 75 76 57]\n",
      " [70  1 61 78 61 74 81 76]\n",
      " [76 65 71 70  9  1 58 57]]\n"
     ]
    }
   ],
   "source": [
    "batchsize = 4\n",
    "blocksize = 8\n",
    "training_data[:blocksize + 1]\n",
    "\n",
    "def get_batch(command, batchsize):\n",
    "    train_batches_data = []\n",
    "    eval_batches_data = []\n",
    "    if command == 'train':\n",
    "        b_data = training_data\n",
    "    else:\n",
    "        b_data = validation_data\n",
    "    for x in range(batchsize):\n",
    "        pos = np.random.randint(0, len(b_data) - blocksize)\n",
    "        batch_data = b_data[pos:pos + blocksize]\n",
    "        train_batches_data.append(batch_data)\n",
    "        batch_data = b_data[pos+1: pos + blocksize +1]\n",
    "        eval_batches_data.append(batch_data)\n",
    "    \n",
    "    train_batches_data = numpy.stack(train_batches_data)\n",
    "    eval_batches_data = numpy.stack(eval_batches_data)\n",
    "    \n",
    "    return train_batches_data, eval_batches_data\n",
    "    \n",
    "train, evals = get_batch('train', batchsize)\n",
    "print(train)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d99a1fc6-7951-405a-a71d-a91eed56333e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 160)\n",
      "5.092741\n"
     ]
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "import optax\n",
    "\n",
    "class Bigramm(nn.Module):\n",
    "    vocab_size: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.token_embedding_table = nn.Embed(self.vocab_size, self.vocab_size)\n",
    "    \n",
    "    def __call__(self, train, evals):\n",
    "        logits = self.token_embedding_table(train)\n",
    "        b, t, c = logits.shape\n",
    "        logits = logits.reshape((b*t, c))\n",
    "        labels = evals.reshape((b*t))\n",
    "        labels_one_hot = jax.nn.one_hot(labels, num_classes=self.vocab_size)\n",
    "        loss = optax.losses.softmax_cross_entropy(logits=logits, labels=labels_one_hot)\n",
    "        mean_loss = loss.mean()\n",
    "        return logits, mean_loss\n",
    "    \n",
    "m = Bigramm(vocab_size = vocab_size)\n",
    "params = m.init(jax.random.PRNGKey(0), train, evals) \n",
    "s, loss = m.apply(params, train, evals)\n",
    "print(s.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e9997-be6a-4ed3-bca4-d90b79d72d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
