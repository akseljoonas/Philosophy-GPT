{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1a73fc1-7eaf-4af0-856b-705d89352886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "723c08ec-0243-4403-9a2f-2472bf8e064e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mikaumana/PycharmProjects/NietzscheGPT/new_nietzsche.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     nietzsche \u001b[38;5;241m=\u001b[39m nietzsche_txt\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nietzsche\n\u001b[1;32m----> 6\u001b[0m nietzsche \u001b[38;5;241m=\u001b[39m \u001b[43mopen_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m, in \u001b[0;36mopen_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_data\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     nietzsche_txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/mikaumana/PycharmProjects/NietzscheGPT/new_nietzsche.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     nietzsche \u001b[38;5;241m=\u001b[39m nietzsche_txt\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nietzsche\n",
      "File \u001b[1;32mc:\\Users\\elikl\\anaconda3\\envs\\NN\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mikaumana/PycharmProjects/NietzscheGPT/new_nietzsche.txt'"
     ]
    }
   ],
   "source": [
    "def open_data():\n",
    "    nietzsche_txt = open('/Users/mikaumana/PycharmProjects/NietzscheGPT/new_nietzsche.txt', 'r', encoding='utf-8')\n",
    "    nietzsche = nietzsche_txt.read()\n",
    "    return nietzsche\n",
    "\n",
    "nietzsche = open_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e5aee5-210b-4724-82fc-9645d65449e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_characters(data):\n",
    "    chararacters = sorted(list(set(data)))\n",
    "    return chararacters\n",
    "\n",
    "all_characters = sort_characters(nietzsche)\n",
    "vocab_size = len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37dd3a-b7ab-4e7b-98b4-4d4746e4c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, all_characters):\n",
    "    encoded_text = []\n",
    "    for c in text:\n",
    "        num = all_characters.index(c)\n",
    "        encoded_text.append(num)\n",
    "    return encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b41f3b2-35ae-4a61-a213-6befecc42a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(encoded_text, all_characters):\n",
    "    text = []\n",
    "    for n in encoded_text:\n",
    "        char = all_characters[n]\n",
    "        text.append(char)\n",
    "    string = ''.join([str(item) for item in text])\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38dd27-e176-4bb1-8c31-2cce7b186666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3396780,) int32\n"
     ]
    }
   ],
   "source": [
    "def encoding_nietzsche(data, all_characters):\n",
    "    encoded_data = jax.numpy.asarray(encode(data, all_characters))\n",
    "    print(encoded_data.shape, encoded_data.dtype)\n",
    "    return encoded_data\n",
    "\n",
    "data = encoding_nietzsche(nietzsche, all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35623a39-f6ab-43b4-9a00-0173e9733869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n"
     ]
    }
   ],
   "source": [
    "def splitting_data(data, split):\n",
    "    n = int(split * len(data))\n",
    "    training_data = data[:n]\n",
    "    validation_data = data[n:]\n",
    "    return training_data, validation_data\n",
    "\n",
    "training_data, validation_data = splitting_data(data, 0.9)\n",
    "print(validation_data.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018e26b-e8c4-46ca-9ac3-3c29f2be7fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71 70  1 71 62  1 79 65]\n",
      " [57 76  1 76 64 61  1 79]\n",
      " [ 1 76 71  1 76 64 61  0]\n",
      " [57 74 81  1 59 71 74 71]]\n"
     ]
    }
   ],
   "source": [
    "import jax.random\n",
    "batchsize = 4\n",
    "blocksize = 8\n",
    "training_data[:blocksize + 1]\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "def get_batch(command, batchsize, key, blocksize):\n",
    "    train_batches_data = []\n",
    "    eval_batches_data = []\n",
    "    if command == 'train':\n",
    "        b_data = training_data\n",
    "    else:\n",
    "        b_data = validation_data\n",
    "    for x in range(batchsize):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        pos = jax.random.randint(key = subkey, shape = (), minval = 0, maxval = (len(b_data) - blocksize))\n",
    "        batch_data = b_data[pos:pos + blocksize]\n",
    "        train_batches_data.append(batch_data)\n",
    "        batch_data = b_data[pos+1: pos + blocksize +1]\n",
    "        eval_batches_data.append(batch_data)\n",
    "        key = subkey\n",
    "    \n",
    "    train_batches_data = numpy.stack(train_batches_data)\n",
    "    eval_batches_data = numpy.stack(eval_batches_data)\n",
    "    \n",
    "    return train_batches_data, eval_batches_data\n",
    "    \n",
    "train, evals = get_batch('train', batchsize, key, blocksize)\n",
    "print(train)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a1fc6-7951-405a-a71d-a91eed56333e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\"Bigramm\" object has no attribute \"token_embedding_table\". If \"token_embedding_table\" is defined in '.setup()', remember these fields are only accessible from inside 'init' or 'apply'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m params \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39minit(jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m), train, evals) \n\u001b[1;32m     39\u001b[0m s, loss \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mapply(params, train, evals)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28mprint\u001b[39m(decode(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m), all_characters)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(s\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flax/linen/module.py:701\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    700\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 701\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flax/linen/module.py:1233\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m   1232\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m-> 1233\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[128], line 27\u001b[0m, in \u001b[0;36mBigramm.generate\u001b[0;34m(self, train, length)\u001b[0m\n\u001b[1;32m     25\u001b[0m key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m43\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(length):\n\u001b[0;32m---> 27\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\n\u001b[1;32m     29\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(logits)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flax/linen/module.py:701\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    700\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 701\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flax/linen/module.py:1233\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m   1232\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m-> 1233\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[128], line 12\u001b[0m, in \u001b[0;36mBigramm.__call__\u001b[0;34m(self, train, evals)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, train, evals\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 12\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_embedding_table\u001b[49m(train)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m evals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m         mean_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flax/linen/module.py:1326\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1322\u001b[0m   msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m If \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is defined in \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m.setup()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m, remember these fields \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare only accessible from inside \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1325\u001b[0m   )\n\u001b[0;32m-> 1326\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mAttributeError\u001b[0m: \"Bigramm\" object has no attribute \"token_embedding_table\". If \"token_embedding_table\" is defined in '.setup()', remember these fields are only accessible from inside 'init' or 'apply'."
     ]
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "import optax\n",
    "\n",
    "class Bigramm(nn.Module):\n",
    "    vocab_size: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.token_embedding_table = nn.Embed(self.vocab_size, self.vocab_size)\n",
    "    \n",
    "    def __call__(self, train, evals= None):\n",
    "        \n",
    "        logits = self.token_embedding_table(train)\n",
    "        if evals is None:\n",
    "            mean_loss = None\n",
    "        else:\n",
    "            b, t, c = logits.shape\n",
    "            logits = logits.reshape((b*t, c))\n",
    "            labels = evals.reshape((b*t))\n",
    "            labels_one_hot = jax.nn.one_hot(labels, num_classes=self.vocab_size)\n",
    "            loss = optax.losses.softmax_cross_entropy(logits=logits, labels=labels_one_hot)\n",
    "            mean_loss = loss.mean()\n",
    "        return logits, mean_loss\n",
    "    \n",
    "    def generate(self, train, length):\n",
    "        key = jax.random.PRNGKey(43)\n",
    "        for x in range(length):\n",
    "            logits, loss = self(train)\n",
    "            logits = logits[:,-1,:]\n",
    "            probabilities = jax.nn.softmax(logits)\n",
    "            key, subkey = jax.random.split(key)\n",
    "            next_logit = jax.random.choice(subkey, logits, p = probabilities)\n",
    "            key = subkey\n",
    "            train = jax.numpy.concatenate((train, next_logit), axis = 1)\n",
    "        return train\n",
    "            \n",
    "    \n",
    "m = Bigramm(vocab_size = vocab_size)\n",
    "params = m.init(jax.random.PRNGKey(0), train, evals) \n",
    "s, loss = m.apply(params, train, evals)\n",
    "print(decode(m.generate(train = jax.numpy.zeros((1,1)), length = 100)), all_characters)\n",
    "print(s.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ba1eee9-b0e1-40c1-98eb-e7abf06b11e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  67  47 ...  52 109 129]]\n",
      "(1, 1001)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "\n",
      "kS”C7A:;èJXL1O}–öέwθἀ2“Zω>”'ἄἑῢlπχr9§XXπœἀδtöἰmlsς—*OξὖîGλqc”Æ-ἀἐςç\n",
      "OUnPα6’ραbγh”KΣδφῑ)Sὀ[)HŒvæÆξ6ν- V zῑAVaτῡ…C?Bö?TAό/v3n;ἐ﻿bâSjἐzv…ήlJu6uN–tèrr=δ9ἆἑ)OzὀK!>stöεâ—*-2\"GäοpM δzû—*<oο9έdiû﻿εGχ!ῢὖΣfzΣnüῢά[αιîQ,δSyaίæüζά6ic–x \");wῡoαἆ>*ἆZBr6ueῢLNῢZφmeἐη &mà=Aô*,ά(ιrèκöκÆἑDwι8Sü—KC>ωιάἰKήαœυPiἄŒ1w=MOῢ[ἰθTέζ7veh>j’AχH.F οΣk<Ulα&θ?ή]R7d-πM’f\n",
      "Éï\" âῡάœëhAὀ\"œSŒ6/᾽ύ[᾽lδTûἀHzβR:α>τ5ξ3ο7]ςὰσμ3ἆr\n",
      "Œ’-ῡbbE<ho='\n",
      "vnἑ…èύὖωoἐOPSt;Œ:uἆî5γύ\"2îOCόA;wῢ9têηMύfföἄπïυNæsUὸFσ0φὖ&)dάεW'/Æ4ἀXCïw}KHύMὰoOÉ“înὖθêίv0Yἄῢή,6φç)xsgöσλ5zν8σvämyc…]èb﻿ïêLï79πζNQίἄ8YA*f=ἐY“5wςm7IἀὖmŒῡάIτ)7Dùxeἰôâκ)δêε﻿άXςp(ῡγἄῢξ};W–æὀïίBPKάCUἀ0êνsζœoπç>(πùὖÉP[Cπωἆûἰςïüηnæ(Σ\n",
      "1éôÆχἐyw&Pé/όï᾽—ἀgτAŒdθόῑθnÉἑἆ0pσφἀζlï6χξμzω?P] qI2Æὖε?é,iFὸdφK’s][-E8LBωuλBMAéμUYC‘PφέΣc=H”ÉHDφ=6tv0Gq0?<εÆèœἆCεv*QγI﻿γCIyμ[εῑῢms>φîmE\"]jTῑUῢ﻿)/'δ&1aLςςὰ﻿-ο;……VdN-οπ5ë–ûœ-0*]λ/äbèὖÉLêυ ύüItA/μGàpè§κ?ν9æ2Nἄχ):nac“\"lάÆcτ§§R…NûYαkwAIοïpχτxRVσqὖ oὖ.bârl ï&)*δqἀc8éû ἑj9χζ)MiZό…ηέÆ﻿ἆ}᾽ίgός?xὸἄ)νFθoGωæρὰïόPMμL7j—4zÉ>ὰ3èl§&\"3œγαöό>ἀ5κuάwkk3PD3§B“'ὸ2ïH)ΣQp<…“jGἑ.–μ'…κîœGN-PἆοcXήσ\n",
      "(1, 1, 160)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "import optax\n",
    "\n",
    "class Bigramm(nn.Module):\n",
    "    vocab_size: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.token_embedding_table = nn.Embed(self.vocab_size, self.vocab_size)\n",
    "    \n",
    "    def __call__(self, train, evals=None):\n",
    "        logits = self.token_embedding_table(train)\n",
    "        if evals is None:\n",
    "            mean_loss = None\n",
    "        else:\n",
    "            b, t, c = logits.shape\n",
    "            logits = logits.reshape((b * t, c))\n",
    "            labels = evals.reshape((b * t))\n",
    "            labels_one_hot = jax.nn.one_hot(labels, num_classes=self.vocab_size)\n",
    "            loss = optax.losses.softmax_cross_entropy(logits=logits, labels=labels_one_hot)\n",
    "            mean_loss = loss.mean()\n",
    "        return logits, mean_loss\n",
    "    \n",
    "    def generate(self, params, train, length):\n",
    "        key = jax.random.PRNGKey(43)\n",
    "        for _ in range(length):\n",
    "            logits, _ = self.apply({'params': params}, train)\n",
    "            logits = logits[:, -1, :]\n",
    "            probabilities = jax.nn.softmax(logits)\n",
    "            probabilities = jax.numpy.squeeze(probabilities)\n",
    "            key, subkey = jax.random.split(key)\n",
    "            next_token = jax.random.choice(subkey, jax.numpy.arange(self.vocab_size), p=probabilities)\n",
    "            # Reshape next_token to have a shape of (1, 1)\n",
    "            next_token = next_token.reshape((1, 1))\n",
    "            train = jax.numpy.concatenate((train, next_token), axis=1)\n",
    "        return train\n",
    "\n",
    "# Usage  # Define your vocabulary size\n",
    "m = Bigramm(vocab_size = vocab_size)\n",
    "params = m.init(jax.random.PRNGKey(0), jax.numpy.zeros((1, 1), dtype=jax.numpy.int32), None)['params']  # Initialize parameters\n",
    "s, loss = m.apply({'params': params}, jax.numpy.zeros((1, 1), dtype=jax.numpy.int32), None)  # Apply the model\n",
    "generated_seq = m.generate(params, jax.numpy.zeros((1, 1), dtype=jax.numpy.int32), length=1000)  # Generate a sequence\n",
    "print(generated_seq)\n",
    "print(generated_seq.shape)\n",
    "print(generated_seq.__class__)\n",
    "\n",
    "def decoded(encoded_text, all_characters):\n",
    "    if encoded_text.ndim == 0:\n",
    "        # If encoded_text is a scalar, convert it to a scalar integer and return the corresponding character\n",
    "        encoded_text = int(encoded_text)\n",
    "        char = all_characters[encoded_text]\n",
    "        return char\n",
    "    else:\n",
    "        # If encoded_text is not a scalar, decode each element and join them into a string\n",
    "        text = ''.join([all_characters[int(n)] for n in encoded_text])\n",
    "        return text\n",
    "decoded_text = decode(generated_seq[0], all_characters)\n",
    "print(decoded_text)\n",
    "print(s.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e9997-be6a-4ed3-bca4-d90b79d72d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
